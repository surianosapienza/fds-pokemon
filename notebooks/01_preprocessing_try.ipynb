{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8266c675",
   "metadata": {},
   "source": [
    "## Loading and Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e14a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7bb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import yaml\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "import src.data_management as my_dm\n",
    "seed=456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41bb073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from '../data/train/raw/train.jsonl'...\n",
      "Successfully loaded 9999 battles.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "train_file_path = config[\"data\"][\"input_train_path\"]\n",
    "test_file_path = config[\"data\"][\"input_test_path\"]\n",
    "\n",
    "train_data = []\n",
    "\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6cdef",
   "metadata": {},
   "source": [
    "This code loads the training data from a JSONL (JSON Lines) file. First, it reads the configuration file to get the file paths for both training and test datasets. Then it reads the training file line by line, where each line contains a JSON object representing a single battle. The json.loads() function parses each line into a Python dictionary, which is then appended to the train_data list. Error handling is included to catch cases where the file might not exist at the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd310efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A very basic feature extraction function.\n",
    "    It only uses the aggregated base stats of the player's team and opponent's lead.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for battle in data:\n",
    "        features = {}\n",
    "        features[\"battle_id\"] = battle.get(\"battle_id\", -1)\n",
    "        if battle.get('player_won') is not None:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "        # --- Player 1 Team Features ---\n",
    "\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if p1_team:\n",
    "            #\"\"\"\n",
    "            stats = ['base_hp', 'base_atk', 'base_def', 'base_spa', 'base_spd', 'base_spe']\n",
    "            for stat in stats:               ### This helps the model to have a better idea abt the time instead of having only mean\n",
    "                values = [p.get(stat, 0) for p in p1_team]\n",
    "                features[f'p1_mean_{stat}'] = np.mean(values)\n",
    "                #features[f'p1_min_{stat}'] = np.min(values)\n",
    "                #features[f'p1_max_{stat}'] = np.max(values)\n",
    "                features[f'p1_std_{stat}'] = np.std(values)\n",
    "            '''\n",
    "            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n",
    "            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n",
    "            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n",
    "            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n",
    "            features['p1_mean_spa'] = np.mean([p.get('base_spa', 0) for p in p1_team])\n",
    "            features['p1_mean_spd'] = np.mean([p.get('base_spd', 0) for p in p1_team])\n",
    "            '''\n",
    "            #features['p1_mean_stats'] = np.mean([features['p1_mean_base_hp'], features['p1_mean_base_spe'], features['p1_mean_base_atk'], features['p1_mean_base_def'], features['p1_mean_base_spa'], features['p1_mean_base_spd']])\n",
    "            \n",
    "            ### We can also build derivated feature like how much is off/def our team\n",
    "            # team stats\n",
    "            base_atk = features['p1_mean_base_atk']\n",
    "            base_spa = features['p1_mean_base_spa']\n",
    "            base_def = features['p1_mean_base_def']\n",
    "            base_spd = features['p1_mean_base_spd']\n",
    "            base_spe = features['p1_mean_base_spe']\n",
    "            base_hp  = features['p1_mean_base_hp']\n",
    "\n",
    "            ## constructing new features\n",
    "            offense = base_atk + base_spa\n",
    "            defense = base_def + base_spd\n",
    "            #features['p1_offense_mean']    = offense\n",
    "            #features['p1_defense_mean']    = defense\n",
    "            features['p1_atk_def_ratio']   = offense / (defense + 1e-6)\n",
    "            # average per-Pokémon total base stats\n",
    "            p1_totals = [sum(p.get(s, 0) for s in stats) for p in p1_team]\n",
    "            features['p1_total_base_power'] = float(np.mean(p1_totals))\n",
    "            features['p1_stat_variety']     = float(np.std(p1_totals))\n",
    "            features['p1_style_index']      = offense / (offense + defense + 1e-6)\n",
    "            features['p1_hp_ratio']         = base_hp / (offense + defense + base_spe + 1e-6)\n",
    "            # fastest member speed (robust comparator vs P2 lead)\n",
    "            features['p1_max_speed']        = float(np.max([p.get('base_spe', 0) for p in p1_team]))\n",
    "        \n",
    "    \n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            '''\n",
    "###########################################AGGIUNTA####################################################\n",
    "          # Estrazione tipi\n",
    "            type_counts = {t: 0 for t in all_types}\n",
    "            for p in p1_team:\n",
    "                for t in p.get('types', []):\n",
    "                    type_counts[t] += 1\n",
    "            team_size = len(p1_team)\n",
    "            for t in all_types:\n",
    "                features[f'p1_type_{t}'] = type_counts[t] / team_size if team_size > 0 else 0\n",
    "##########################################AGGIUNTA#####################################################\n",
    "            '''\n",
    "            \"\"\"\n",
    "        # --- Player 2 Lead Features ---\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        \n",
    "        if p2_lead:\n",
    "            # Player 2's lead Pokémon's stats\n",
    "            features['p2_lead_hp'] = p2_lead.get('base_hp', 0)\n",
    "            features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n",
    "            features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n",
    "            features['p2_lead_def'] = p2_lead.get('base_def', 0)\n",
    "            features['p2_lead_spd'] = p2_lead.get('base_spd', 0)\n",
    "            features['p2_lead_spa'] = p2_lead.get('base_spa', 0)\n",
    "            ## types of p2 lead\n",
    "            for t in all_types:\n",
    "                features[f'p2_lead_type_{t}'] = 0.0\n",
    "            for t in p2_lead.get('types', []):\n",
    "                if t in all_types:\n",
    "                    features[f'p2_lead_type_{t}'] = 1.0\n",
    "               \n",
    "            \"\"\"\n",
    "        ## Extracting battle features\n",
    "        timeline = battle.get(\"battle_timeline\", [])\n",
    "        if len(timeline) > 0:\n",
    "            #\"\"\"\n",
    "            # Average HP percentage for both players\n",
    "            p1_hp = [turn[\"p1_pokemon_state\"].get(\"hp_pct\", np.nan) for turn in timeline]\n",
    "            p2_hp = [turn[\"p2_pokemon_state\"].get(\"hp_pct\", np.nan) for turn in timeline]\n",
    "\n",
    "            features[\"p1_mean_hp_pct\"] = np.nanmean(p1_hp)\n",
    "            features[\"p2_mean_hp_pct\"] = np.nanmean(p2_hp)\n",
    "            features[\"p1_final_hp\"] = p1_hp[-1]\n",
    "            features[\"p2_final_hp\"] = p2_hp[-1]\n",
    "            features[\"p1_total_damage\"] = np.nansum(np.maximum(0, np.diff(p1_hp)))\n",
    "            features[\"p2_total_damage\"] = np.nansum(np.maximum(0, np.diff(p2_hp)))\n",
    "\n",
    "            # Count total moves used\n",
    "            p1_moves = [turn.get(\"p1_move_details\", {}).get(\"name\") for turn in timeline if turn.get(\"p1_move_details\")]\n",
    "            p2_moves = [turn.get(\"p2_move_details\", {}).get(\"name\") for turn in timeline if turn.get(\"p2_move_details\")]\n",
    "            p1_totmoves= features[\"p1_total_moves\"] = len(p1_moves)\n",
    "            p2_totmoves= features[\"p2_total_moves\"] = len(p2_moves)\n",
    "            features[\"total_moves_difference\"] = p2_totmoves-p1_totmoves\n",
    "\n",
    "            # Count unique move types used\n",
    "            p1_move_types = [turn[\"p1_move_details\"].get(\"type\") for turn in timeline if turn.get(\"p1_move_details\")]\n",
    "            p2_move_types = [turn[\"p2_move_details\"].get(\"type\") for turn in timeline if turn.get(\"p2_move_details\")]\n",
    "            p1_unique= features[\"p1_unique_move_types\"] = len(set(p1_move_types))\n",
    "            p2_unique= features[\"p2_unique_move_types\"] = len(set(p2_move_types))\n",
    "            features[\"unique_moves_difference\"]=p1_unique-p2_unique\n",
    "            #\"\"\"\n",
    "\n",
    "            p1_pkmns =  set([turn[\"p1_pokemon_state\"][\"name\"] for turn in timeline])\n",
    "            p2_pkmns = set([turn[\"p2_pokemon_state\"][\"name\"] for turn in timeline])\n",
    "\n",
    "            ### status and effects features\n",
    "            total_statuses = ['slp', 'fnt', 'tox', 'psn', 'brn', 'frz', 'par', 'nostatus']\n",
    "            p1_status = [turn[\"p1_pokemon_state\"].get(\"status\") for turn in timeline]\n",
    "            p2_status = [turn[\"p2_pokemon_state\"].get(\"status\") for turn in timeline]\n",
    "\n",
    "            total_effects = ['disable', 'firespin', 'confusion', 'substitute', 'wrap', 'clamp', 'typechange', 'reflect', 'noeffect']\n",
    "            p1_effects = [turn[\"p1_pokemon_state\"].get(\"effects\") for turn in timeline]\n",
    "            p1_effects = [effect for effects in p1_effects for effect in effects]\n",
    "            p2_effects = [turn[\"p2_pokemon_state\"].get(\"effects\") for turn in timeline]\n",
    "            p2_effects = [effect for effects in p2_effects for effect in effects]\n",
    "\n",
    "            ## general status features\n",
    "\n",
    "            # Count probably critical moves\n",
    "            \n",
    "            p1_moves_used = [t[\"p1_move_details\"][\"name\"] for t in timeline if t.get(\"p1_move_details\")]\n",
    "            p2_moves_used = [t[\"p2_move_details\"][\"name\"] for t in timeline if t.get(\"p2_move_details\")]\n",
    "            high_crit = {\"Crabhammer\", \"Karate Chop\", \"Razor Leaf\", \"Slash\", \"crabhammer\", \"karate chop\", \"razor leaf\", \"slash\"}\n",
    "\n",
    "            high1 = features[\"p1_highcrit_moves_used\"] = sum(m in high_crit for m in p1_moves_used)\n",
    "            high2 = features[\"p2_highcrit_moves_used\"] = sum(m in high_crit for m in p2_moves_used)\n",
    "            features[\"highcrit_difference\"]=high1-high2\n",
    "\n",
    "            # Count total statuses inflicted\n",
    "            \n",
    "            \n",
    "            changeofstatus_1= features[\"p1_status_changes\"] = sum(1 for s in p1_status if s not in [\"nostatus\", \"noeffect\", None])\n",
    "            changeofstatus_2= features[\"p2_status_changes\"] = sum(1 for s in p2_status if s not in [\"nostatus\", \"noeffect\", None])\n",
    "            features[\"status_changes_difference\"]= changeofstatus_1-changeofstatus_2\n",
    "            \n",
    "            # Count single status count \n",
    "\n",
    "            dict_status_p1 = {status : 0 for status in total_statuses}\n",
    "            dict_status_p2 = {status : 0 for status in total_statuses}\n",
    "            for turn in timeline:\n",
    "                if turn[\"p1_pokemon_state\"].get(\"status\"):\n",
    "                    turn_status = turn[\"p1_pokemon_state\"].get(\"status\")\n",
    "                    dict_status_p1[turn_status] += 1\n",
    "                if turn[\"p2_pokemon_state\"].get(\"status\"):\n",
    "                    turn_status = turn[\"p2_pokemon_state\"].get(\"status\")\n",
    "                    dict_status_p2[turn_status] += 1\n",
    "            \n",
    "            for status in total_statuses:\n",
    "                features[f\"p1_{status}_count\"] = dict_status_p1.get(status, 0)\n",
    "                features[f\"p2_{status}_count\"] = dict_status_p2.get(status, 0)\n",
    "                \n",
    "\n",
    "            ## fnt features\n",
    "            \n",
    "            # Difference in fnt pkmn\n",
    "\n",
    "            features[\"p2-p1_fnt_pokemon_number\"] = features[\"p1_fnt_count\"] - features[\"p2_fnt_count\"]\n",
    "\n",
    "            # fnt pkmn over total pokemon\n",
    "\n",
    "            #features[\"p1_fnt_over_total_pkmn\"] = features[\"p1_fnt_count\"]/6\n",
    "            #features[\"p2_fnt_over_total_pkmn\"] = features[\"p2_fnt_count\"]/6\n",
    "            '''\n",
    "            ## Pokémon blocked features\n",
    "\n",
    "            blocking_statuses = ['slp', 'frz']\n",
    "\n",
    "            # blocked pokémon (sleep or freeze)\n",
    "            features[\"p1_blocked_count\"] = sum(dict_status_p1[s] for s in blocking_statuses)\n",
    "            features[\"p2_blocked_count\"] = sum(dict_status_p2[s] for s in blocking_statuses)\n",
    "\n",
    "            # difference\n",
    "            features[\"p2-p1_blocked_status_diff\"] = (\n",
    "                features[\"p2_blocked_count\"] - features[\"p1_blocked_count\"]\n",
    "            )\n",
    "\n",
    "            # normalized over total team size (6)\n",
    "            features[\"p1_blocked_over_total_pkmn\"] = features[\"p1_blocked_count\"] / 6\n",
    "            features[\"p2_blocked_over_total_pkmn\"] = features[\"p2_blocked_count\"] / 6\n",
    "            '''\n",
    "\n",
    "\n",
    "            ## effects features\n",
    "\n",
    "            # Count turns with effects like \"reflect\", \"light screen\", etc.\n",
    "\n",
    "            dict_effects_p1 = {effect : 0 for effect in total_effects}\n",
    "            dict_effects_p2 = {effect : 0 for effect in total_effects}\n",
    "            for turn in timeline:\n",
    "                if turn[\"p1_pokemon_state\"].get(\"effects\"):\n",
    "                    turn_effects_p1 = turn[\"p1_pokemon_state\"].get(\"effects\")\n",
    "                    for effect in turn_effects_p1:\n",
    "                        dict_effects_p1[effect] += 1\n",
    "                if turn[\"p2_pokemon_state\"].get(\"effects\"):\n",
    "                    turn_effects_p2 = turn[\"p2_pokemon_state\"].get(\"effects\")\n",
    "                    for effect in turn_effects_p2:\n",
    "                        dict_effects_p2[effect] += 1            \n",
    "            for effect in total_effects:\n",
    "                features[f\"p1_{effect}_count\"] = dict_effects_p1.get(effect, 0)\n",
    "                features[f\"p2_{effect}_count\"] = dict_effects_p2.get(effect, 0)\n",
    "\n",
    "            # Boosts (attack, defense, etc.)\n",
    "            #boost_keys = [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]\n",
    "            #for key in boost_keys:\n",
    "            #    p1_boosts = [turn[\"p1_pokemon_state\"][\"boosts\"].get(key, 0) for turn in timeline]\n",
    "            #    p2_boosts = [turn[\"p2_pokemon_state\"][\"boosts\"].get(key, 0) for turn in timeline]\n",
    "            #    features[f\"p1_mean_boost_{key}\"] = np.mean(p1_boosts)\n",
    "            #    features[f\"p2_mean_boost_{key}\"] = np.mean(p2_boosts)\n",
    "\n",
    "            # Number of time the player switched pokemon\n",
    "            features[\"p1_switch_number\"] = sum([1 for turn in timeline if turn[\"p1_move_details\"] == None])\n",
    "            features[\"p2_switch_number\"] = sum([1 for turn in timeline if turn[\"p2_move_details\"] == None])\n",
    "            features[\"switchnumber_difference\"] = features[\"p1_switch_number\"]-features[\"p2_switch_number\"]\n",
    "            # Number of SPECIAL or PHYSICAL moves and Number of STATUS moves of p1 and p2\n",
    "            features[\"p1_attack_moves\"] = sum([1 for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p2_attack_moves\"] = sum([1 for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p1_status_moves\"] = sum([1 for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"][\"category\"] not in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p2_status_moves\"] = sum([1 for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"category\"] not in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "\n",
    "            # Number of same pokemon type moves (stab)\n",
    "            features[\"p1_same_type_moves_number\"] = sum([1 for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"][\"type\"] in my_dm.pokemon_type(turn[\"p1_pokemon_state\"][\"name\"]) and turn[\"p1_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p2_same_type_moves_number\"] = sum([1 for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"type\"] in my_dm.pokemon_type(turn[\"p2_pokemon_state\"][\"name\"]) and turn[\"p2_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "\n",
    "            # Average of multiplier effectivness\n",
    "            def safe_nanmean(lst):\n",
    "                return 0 if len(lst) == 0 else np.nanmean(lst)\n",
    "            features[\"p1_effectivness_avg\"] = safe_nanmean([my_dm.move_effectiveness(turn[\"p1_move_details\"][\"type\"], turn[\"p2_pokemon_state\"][\"name\"]) for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p2_effectivness_avg\"] = safe_nanmean([my_dm.move_effectiveness(turn[\"p2_move_details\"][\"type\"], turn[\"p1_pokemon_state\"][\"name\"]) for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "\n",
    "            # Number of supereffective moves\n",
    "            features[\"p1_supereffective_moves_count\"] = sum([my_dm.is_supereffective(my_dm.move_effectiveness(turn[\"p1_move_details\"][\"type\"], turn[\"p2_pokemon_state\"][\"name\"])) for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            features[\"p2_supereffective_moves_count\"] = sum([my_dm.is_supereffective(my_dm.move_effectiveness(turn[\"p2_move_details\"][\"type\"], turn[\"p1_pokemon_state\"][\"name\"])) for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]])\n",
    "            \n",
    "            # Sum of priority moves\n",
    "            features[\"p1_priority_moves\"] = sum([1 for turn in timeline if turn.get(\"p1_move_details\") and turn[\"p1_move_details\"].get(\"priority\")])\n",
    "            features[\"p2_priority_moves\"] = sum([1 for turn in timeline if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"].get(\"priority\")])\n",
    "\n",
    "            # Number of supereffective pokemon of p1 in respect to p2 \n",
    "\n",
    "            features[\"p1_supereffective_density\"] = sum(1 for pkmn1 in p1_pkmns for pkmn2 in p2_pkmns if my_dm.is_supereffective(my_dm.pkmn_effectiveness(pkmn1, pkmn2)))/(len(p1_pkmns)*len(p2_pkmns))\n",
    "            features[\"p2_supereffective_density\"] = sum(1 for pkmn1 in p1_pkmns for pkmn2 in p2_pkmns if my_dm.is_supereffective(my_dm.pkmn_effectiveness(pkmn2, pkmn1)))/(len(p1_pkmns)*len(p2_pkmns))\n",
    "            features[\"p1-p2_se_densities\"] = features[\"p2_supereffective_density\"] - features[\"p1_supereffective_density\"]\n",
    "\n",
    "            # P1 pkmn having at least a supereffective target in p2 team\n",
    "            features[\"p1_attackers_share\"] = sum(any(my_dm.is_supereffective(my_dm.pkmn_effectiveness(pkmn1, pkmn2)) for pkmn2 in p2_pkmns) for pkmn1 in p1_pkmns) / len(p1_pkmns)\n",
    "\n",
    "            # P1 pkmn that are target of at least one pkmn in team 2\n",
    "            features[\"p1_defensive_share\"] = sum(any(my_dm.is_supereffective(my_dm.pkmn_effectiveness(pkmn2, pkmn1)) for pkmn2 in p2_pkmns) for pkmn1 in p1_pkmns) / len(p2_pkmns)\n",
    "\n",
    "            # mean of hp percentage for p1 team and p2 team on last informations\n",
    "            p1_hp_pctg = {p1_pkmn : None for p1_pkmn in p1_pkmns}\n",
    "            p2_hp_pctg = {p2_pkmn : None for p2_pkmn in p2_pkmns}\n",
    "            counter1 = 0\n",
    "            counter2 = 0\n",
    "            for turn in timeline:\n",
    "                p1_hp_pctg.update({turn[\"p1_pokemon_state\"][\"name\"] : turn[\"p1_pokemon_state\"][\"hp_pct\"]})\n",
    "                p2_hp_pctg.update({turn[\"p2_pokemon_state\"][\"name\"] : turn[\"p2_pokemon_state\"][\"hp_pct\"]})\n",
    "\n",
    "                counter1 += turn[\"p1_pokemon_state\"][\"hp_pct\"] > turn[\"p2_pokemon_state\"][\"hp_pct\"]\n",
    "                counter2 += turn[\"p1_pokemon_state\"][\"hp_pct\"] < turn[\"p2_pokemon_state\"][\"hp_pct\"]\n",
    "            features[\"p1_remain_health_avg\"] = sum(p1_hp_pctg.values())/len(p1_pkmns)\n",
    "            features[\"p2_remain_health_avg\"] = sum(p2_hp_pctg.values())/len(p2_pkmns)\n",
    "            features[\"health_difference\"] = features[\"p2_remain_health_avg\"] - features[\"p1_remain_health_avg\"]\n",
    "            \n",
    "            features[\"health_advantage_p1\"]= counter1\n",
    "            features[\"health_advantage_p2\"]= counter2\n",
    "            features[\"health_advantage_difference\"]= counter1 - counter2\n",
    "            hp_advantage_streak = sum(p1 > p2 for p1, p2 in zip(p1_hp_pctg, p2_hp_pctg))\n",
    "            features[\"p1_hp_advantage_final_ratio\"] = hp_advantage_streak \n",
    "\n",
    "            features[\"remaining_advantage\"] = (\n",
    "                features[\"p1_remain_health_avg\"] * (1-features[\"p1_fnt_count\"])\n",
    "                - features[\"p2_remain_health_avg\"] * (1-features[\"p2_fnt_count\"])\n",
    "            )\n",
    "\n",
    "        feature_list.append(features)\n",
    "        \n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353cd420",
   "metadata": {},
   "source": [
    "This function create_simple_features() performs the extraction of numerical features from the raw Pokémon battle data.\n",
    "For each battle in the dataset, it builds a dictionary of features that describe statistics of the player’s team (Player 1), the opponent’s lead Pokémon (Player 2 lead), and the battle progression (timeline).\n",
    "The features include:\n",
    "\n",
    "Aggregated base stats of the player’s team (p1): mean, minimum, maximum, and standard deviation for each stat (HP, Attack, Defense, etc.).\n",
    "\n",
    "Derived features: indices such as average total power, attack/defense ratio, offensive/defensive style, and the team’s maximum speed.\n",
    "\n",
    "Opponent lead stats (p2): base values and one-hot encoding of Pokémon types.\n",
    "\n",
    "Temporal characteristics of the battle: variations in average HP, total damage taken, and counts/types of moves used.\n",
    "\n",
    "Status and field effects: counts of conditions (e.g., “burned”, “poisoned”, “asleep”) and effects (e.g., “reflect”, “wrap”) for both players.\n",
    "\n",
    "Tactical metrics: number of switches, use of priority moves, super-effective moves, and same-type moves (STAB).\n",
    "\n",
    "Advantage indicators: density of favorable matchups, average remaining HP, health differences, and count of turns with HP advantage.\n",
    "\n",
    "Finally, the function returns a pandas DataFrame containing all extracted features, replacing any missing values with zero (fillna(0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08808721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dragon', 'electric', 'fire', 'flying', 'ghost', 'grass', 'ground', 'ice', 'normal', 'notype', 'poison', 'psychic', 'rock', 'water']\n",
      "{'dragon': 0.0, 'electric': 0.0, 'fire': 0.0, 'flying': 0.0, 'ghost': 0.0, 'grass': 0.16666666666666666, 'ground': 0.0, 'ice': 0.0, 'normal': 0.5, 'notype': 0.6666666666666666, 'poison': 0.0, 'psychic': 0.5, 'rock': 0.0, 'water': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "all_types = set()\n",
    "for battle in train_data:\n",
    "    for p in battle['p1_team_details']:\n",
    "        all_types.update(p['types'])\n",
    "\n",
    "all_types = sorted(list(all_types))\n",
    "print(all_types)\n",
    "\n",
    "\n",
    "\n",
    "def extract_type_features(team):\n",
    "    type_counts = {t: 0 for t in all_types}\n",
    "    for p in team:\n",
    "        for t in p['types']:\n",
    "            type_counts[t] += 1\n",
    "    \n",
    "    team_size = len(team)\n",
    "    for t in type_counts:\n",
    "        type_counts[t] /= team_size\n",
    "    return type_counts\n",
    "\n",
    "team = train_data[0]['p1_team_details']\n",
    "type_features = extract_type_features(team)\n",
    "print(type_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fb65c",
   "metadata": {},
   "source": [
    "This code extracts and processes Pokemon type features from the training data. First, it iterates through all battles to collect every unique Pokemon type that appears in the dataset, storing them in a sorted list. The extract_type_features() function then calculates the normalized distribution of types within a team by counting how many Pokemon of each type are present and dividing by the team size. This normalization ensures that the features are comparable across teams of different sizes. The function returns a dictionary where keys are Pokemon types and values are their relative frequencies within the team (ranging from 0 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08fdb8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 ,\n",
      "2770 ,\n",
      "3447 ,\n",
      "3453 ,\n",
      "3769 ,\n",
      "6375 ,\n",
      "7642 ,\n",
      "7775 ,\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for battle in train_data:\n",
    "    a = [my_dm.move_effectiveness(turn[\"p1_move_details\"][\"type\"], turn[\"p2_pokemon_state\"][\"name\"]) for turn in battle[\"battle_timeline\"] if turn.get(\"p1_move_details\") and (turn[\"p1_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"])]\n",
    "    a = [my_dm.move_effectiveness(turn[\"p2_move_details\"][\"type\"], turn[\"p1_pokemon_state\"][\"name\"]) for turn in battle[\"battle_timeline\"] if turn.get(\"p2_move_details\") and turn[\"p2_move_details\"][\"category\"] in [\"SPECIAL\", \"PHYSICAL\"]]\n",
    "    if len(a) == 0:\n",
    "        print(i, \",\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd02f6",
   "metadata": {},
   "source": [
    "This code analyzes move effectiveness throughout the battle timeline for both players. For each battle, it extracts all offensive moves (SPECIAL or PHYSICAL category) used by both players and calculates their type effectiveness against the opponent's active Pokemon using the my_dm.move_effectiveness() function. The code checks for battles where player 2 has no offensive moves recorded in the timeline (len(a) == 0) and prints their indices. This helps identify potential data quality issues or battles that ended without player 2 making any attacking moves. Note that the variable 'a' is overwritten in the second list comprehension, so only player 2's move effectiveness is ultimately checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a34aaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance_features(df, threshold=0.999):\n",
    "    to_drop = []\n",
    "    for col in df.columns:\n",
    "        top_freq = df[col].value_counts(normalize=True, dropna=False).iloc[0]\n",
    "        if top_freq >= threshold:\n",
    "            to_drop.append(col)\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51db490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcor\n",
    "def high_nonlinear_corr(df, threshold=0.99):\n",
    "\n",
    "    df_num = df.select_dtypes(include=[np.number])\n",
    "    cols = df_num.columns\n",
    "    n = len(cols)\n",
    "    to_drop = set()\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            x = df_num.iloc[:, i].dropna()\n",
    "            y = df_num.iloc[:, j].dropna()\n",
    "            common_idx = x.index.intersection(y.index)\n",
    "            x = x.loc[common_idx]\n",
    "            y = y.loc[common_idx]\n",
    "\n",
    "            if len(x) > 2:\n",
    "                dcor_value = dcor.distance_correlation(x, y)\n",
    "                if dcor_value > threshold:\n",
    "                    to_drop.add(cols[j])\n",
    "\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d95802",
   "metadata": {},
   "source": [
    "This function identifies low-variance features in a dataframe that have minimal predictive value. It iterates through each column and calculates the frequency of the most common value (including missing values). If the most frequent value appears in 99% or more of the rows (by default), the column is flagged for removal. Such features provide little information for model training since they are nearly constant across all samples. The function returns a list of column names that meet this low-variance criterion and should be considered for removal during feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10bd82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "feature to remove: ['p1_mean_base_spd', 'p1_std_base_spd', 'p1_style_index', 'p1_hp_ratio', 'p1_nostatus_count', 'p2_nostatus_count', 'p2-p1_fnt_pokemon_number', 'p2_typechange_count', 'p1_noeffect_count', 'p2_noeffect_count', 'p1_switch_number', 'p2_switch_number', 'switchnumber_differebnce', 'health_advantage_difference'] ['p1_psn_count', 'p2_psn_count', 'p1_brn_count', 'p2_brn_count', 'p1_disable_count', 'p2_disable_count', 'p1_firespin_count', 'p2_firespin_count', 'p1_wrap_count', 'p2_wrap_count', 'p1_clamp_count', 'p2_clamp_count', 'p1_typechange_count']\n",
      "\n",
      "Processing test data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create feature DataFrames for both training and test sets\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "train_df = train_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "### removing correlations\n",
    "corr_matrix = train_df.corr().abs()\n",
    "upper = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "threshold = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold) and column!='player_won']\n",
    "\n",
    "train_df = train_df.drop(columns=to_drop)\n",
    "\n",
    "# removing low variance\n",
    "\n",
    "\n",
    "to_drop2 = low_variance_features(train_df, threshold=0.99)\n",
    "train_df = train_df.drop(columns=to_drop2)\n",
    "\n",
    "print(\"feature to remove:\", to_drop, to_drop2)\n",
    "## exporting in csv\n",
    "train_df.to_csv(config[\"data\"][\"processed_train_path\"], index=False)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "test_df =test_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "## removing correlations in test\n",
    "test_df = test_df.drop(columns=to_drop)\n",
    "test_df = test_df.drop(columns=to_drop2)\n",
    "\n",
    "test_df.to_csv(config[\"data\"][\"processed_test_path\"], index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb527d",
   "metadata": {},
   "source": [
    "This code performs feature engineering and preprocessing on both training and test datasets. It starts by creating features from the raw training data and shuffling the rows with a fixed random seed for reproducibility. Two feature selection steps are then applied: first, highly correlated features are identified by computing the correlation matrix and removing features with correlation above 0.9 (excluding the target variable 'player_won'); second, low-variance features are removed using a 99% threshold. The processed training data is saved to CSV. The same preprocessing pipeline is then applied to the test data, ensuring that the exact same features identified for removal in training are also dropped from the test set to maintain consistency. Both datasets are shuffled with the same random seed before being saved to their respective output paths specified in the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20a4b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battle_id: -0.866\n",
      "player_won: 1.000\n",
      "p1_mean_hp_pct: 0.378\n",
      "p2_mean_hp_pct: -0.227\n",
      "p1_final_hp: 0.201\n",
      "p1_total_damage: -0.416\n",
      "p2_total_damage: 0.321\n",
      "p1_total_moves: 0.366\n",
      "p2_total_moves: -0.338\n",
      "total_moves_difference: -0.457\n",
      "p1_status_changes: -0.365\n",
      "p2_status_changes: 0.351\n",
      "status_changes_difference: -0.468\n",
      "p1_slp_count: -0.319\n",
      "p2_slp_count: 0.346\n",
      "p1_fnt_count: -0.463\n",
      "p2_frz_count: 0.208\n",
      "p1_attack_moves: 0.261\n",
      "p2_attack_moves: -0.304\n",
      "p2_same_type_moves_number: -0.223\n",
      "p1_remain_health_avg: 0.446\n",
      "p2_remain_health_avg: -0.283\n",
      "health_difference: -0.559\n",
      "health_advantage_p1: 0.333\n",
      "health_advantage_p2: -0.333\n",
      "remaining_advantage: 0.354\n"
     ]
    }
   ],
   "source": [
    "corrs = train_df.corrwith(train_df[\"player_won\"])\n",
    "\n",
    "# print features with |correlation| > 0.5\n",
    "for feature, corr_value in corrs.items():\n",
    "    if abs(corr_value) >0.2:\n",
    "        print(f\"{feature}: {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f4b67",
   "metadata": {},
   "source": [
    "This code calculates and displays the correlation between each feature and the target variable 'player_won'. The corrwith() method computes the Pearson correlation coefficient between every column in the dataframe and the target column. Features with an absolute correlation value greater than 0.2 are printed along with their correlation coefficient rounded to three decimal places. This analysis helps identify which features have the strongest linear relationships with the outcome, providing insights into which variables might be most important for predicting battle victories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9fb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fb4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99b9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
