{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8266c675",
   "metadata": {},
   "source": [
    "## Loading and Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e14a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e41bb073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from '../data/raw/train.jsonl'...\n",
      "Successfully loaded 10000 battles.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "train_file_path = config[\"data\"][\"input_train_path\"]\n",
    "test_file_path = config[\"data\"][\"input_test_path\"]\n",
    "\n",
    "train_data = []\n",
    "\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10bd82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dragon': 0.0, 'electric': 0.0, 'fire': 0.0, 'flying': 0.0, 'ghost': 0.0, 'grass': 0.16666666666666666, 'ground': 0.0, 'ice': 0.0, 'normal': 0.5, 'notype': 0.6666666666666666, 'poison': 0.0, 'psychic': 0.5, 'rock': 0.0, 'water': 0.16666666666666666}\n",
      "Processing training data...\n",
      "\n",
      "Processing test data...\n"
     ]
    }
   ],
   "source": [
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A very basic feature extraction function.\n",
    "    It only uses the aggregated base stats of the player's team and opponent's lead.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for battle in data:\n",
    "        features = {}\n",
    "        \n",
    "        # --- Player 1 Team Features ---\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if p1_team:\n",
    "            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n",
    "            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n",
    "            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n",
    "            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n",
    "            \n",
    "###########################################AGGIUNTA####################################################\n",
    "          # Estrazione tipi\n",
    "            type_counts = {t: 0 for t in all_types}\n",
    "            for p in p1_team:\n",
    "                for t in p.get('types', []):\n",
    "                    type_counts[t] += 1\n",
    "            team_size = len(p1_team)\n",
    "            for t in all_types:\n",
    "                features[f'p1_type_{t}'] = type_counts[t] / team_size if team_size > 0 else 0\n",
    "##########################################AGGIUNTA#####################################################\n",
    "        \n",
    "        # --- Player 2 Lead Features ---\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        if p2_lead:\n",
    "            # Player 2's lead Pok√©mon's stats\n",
    "            features['p2_lead_hp'] = p2_lead.get('base_hp', 0)\n",
    "            features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n",
    "            features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n",
    "            features['p2_lead_def'] = p2_lead.get('base_def', 0)\n",
    "\n",
    "        features['battle_id'] = battle.get('battle_id')\n",
    "        if battle.get('player_won') is not None:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "\n",
    "\n",
    "        feature_list.append(features)\n",
    "        \n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "all_types = set()\n",
    "for battle in train_data:\n",
    "    for p in battle['p1_team_details']:\n",
    "        all_types.update(p['types'])\n",
    "\n",
    "all_types = sorted(list(all_types))\n",
    "\n",
    "\n",
    "\n",
    "def extract_type_features(team):\n",
    "    type_counts = {t: 0 for t in all_types}\n",
    "    for p in team:\n",
    "        for t in p['types']:\n",
    "            type_counts[t] += 1\n",
    "    \n",
    "    team_size = len(team)\n",
    "    for t in type_counts:\n",
    "        type_counts[t] /= team_size\n",
    "    return type_counts\n",
    "\n",
    "team = train_data[0]['p1_team_details']\n",
    "type_features = extract_type_features(team)\n",
    "print(type_features)\n",
    "\n",
    "        ########################################################################################\n",
    "        #####################################AGGIUNTA###########################################\n",
    "        ########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create feature DataFrames for both training and test sets\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "train_df.to_csv(config[\"data\"][\"processed_train_path\"], index=False)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "test_df.to_csv(config[\"data\"][\"processed_test_path\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
